{
    "cells": [
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(train_dir='mnist', one_hot=True)\nmnist",
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Extracting mnist/train-images-idx3-ubyte.gz\nExtracting mnist/train-labels-idx1-ubyte.gz\nExtracting mnist/t10k-images-idx3-ubyte.gz\nExtracting mnist/t10k-labels-idx1-ubyte.gz\n",
                    "name": "stdout"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 6,
                    "data": {
                        "text/plain": "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7ff0ab5c3240>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7ff0ab5c3198>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7ff0ab5c3748>)"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "learning_rate = 0.01\ntraining_epochs = 20\nbatch_size = 256\ndisplay_step = 1\nexamples_to_show = 10\n\n\n\nn_hidden_1 = 256 # 1st layer num features\nn_hidden_2 = 128 # 2nd layer num features\nn_input = 784 # MNIST data input (img shape: 28*28)\n\n\n\n# tf Graph input (only pictures)\nX = tf.placeholder(\"float\", [None, n_input])\n\nweights = {\n    'encoder_h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n    'encoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n    'decoder_h1': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_1])),\n    'decoder_h2': tf.Variable(tf.random_normal([n_hidden_1, n_input])),\n}\nbiases = {\n    'encoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n    'encoder_b2': tf.Variable(tf.random_normal([n_hidden_2])),\n    'decoder_b1': tf.Variable(tf.random_normal([n_hidden_1])),\n    'decoder_b2': tf.Variable(tf.random_normal([n_input])),\n}",
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "WARNING:tensorflow:From /opt/conda/envs/Python36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Building the encoder\ndef encoder(x):\n    # Encoder first layer with sigmoid activation #1\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['encoder_h1']), biases['encoder_b1']))\n    # Encoder second layer with sigmoid activation #2\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['encoder_h2']), biases['encoder_b2']))\n    return layer_2",
            "execution_count": 8,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Building the decoder\ndef decoder(x):\n    # Decoder first layer with sigmoid activation #1\n    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(x, weights['decoder_h1']),biases['decoder_b1']))\n    # Decoder second layer with sigmoid activation #2\n    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, weights['decoder_h2']), biases['decoder_b2']))\n    return layer_2",
            "execution_count": 9,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Construct model\nencoder_op = encoder(X)\ndecoder_op = decoder(encoder_op)\n\n# Reconstructed Images\ny_pred = decoder_op\n# Targets (Labels) are the input data.\ny_true = X\n\n# Define loss and optimizer, minimize the squared error\ncost = tf.reduce_mean(tf.pow(y_true - y_pred, 2))\noptimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n\n# Initializing the variables\ninit = tf.global_variables_initializer()",
            "execution_count": 10,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Launch the graph\n# Using InteractiveSession (more convenient while using Notebooks)\nsess = tf.InteractiveSession()\nsess.run(init)\n\ntotal_batch = int(mnist.train.num_examples / batch_size)\n# Training cycle\nfor epoch in range(training_epochs):\n    # Loop over all batches\n    for i in range(total_batch):\n        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n        # Run optimization op (backprop) and cost op (to get loss value)\n        _, c = sess.run([optimizer, cost], feed_dict={X: batch_xs})\n    # Display logs per epoch step\n    if epoch % display_step == 0:\n        print(\"Epoch:\", '%04d' % (epoch+1),\n              \"cost=\", \"{:.9f}\".format(c))\n\nprint(\"Optimization Finished!\")",
            "execution_count": 11,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Epoch: 0001 cost= 0.215042695\nEpoch: 0002 cost= 0.179553136\nEpoch: 0003 cost= 0.163513288\nEpoch: 0004 cost= 0.151734278\nEpoch: 0005 cost= 0.147248745\nEpoch: 0006 cost= 0.137515813\nEpoch: 0007 cost= 0.134325176\nEpoch: 0008 cost= 0.131061122\nEpoch: 0009 cost= 0.123258784\nEpoch: 0010 cost= 0.120644309\nEpoch: 0011 cost= 0.117808290\nEpoch: 0012 cost= 0.119189270\nEpoch: 0013 cost= 0.113165721\nEpoch: 0014 cost= 0.111913487\nEpoch: 0015 cost= 0.110598288\nEpoch: 0016 cost= 0.111783661\nEpoch: 0017 cost= 0.108505853\nEpoch: 0018 cost= 0.109056279\nEpoch: 0019 cost= 0.108281679\nEpoch: 0020 cost= 0.109303959\nOptimization Finished!\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Applying encode and decode over test set\nencode_decode = sess.run(\n    y_pred, feed_dict={X: mnist.test.images[:examples_to_show]})",
            "execution_count": 12,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Compare original images with their reconstructions\nf, a = plt.subplots(2, 10, figsize=(10, 2))\nfor i in range(examples_to_show):\n    a[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n    a[1][i].imshow(np.reshape(encode_decode[i], (28, 28)))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}